{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "tjbNgyV44rbg"
   },
   "source": [
    "# Install all the required dependencies for the project\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install spacy==2.2.4\n",
    "!python -m spacy download en_core_web_md\n",
    "!pip install scikit-learn==1.0.2\n",
    "!pip install matplotlib # to render Confusion Matrix\n",
    "!pip install seaborn # to render Confusion Matrix"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTWZJAqiBxEv"
   },
   "source": [
    "Import all the necessary libraries we need throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CQKGy3Um4whH"
   },
   "source": [
    "# Import all the relevant libraries\n",
    "import spacy\n",
    "import en_core_web_md\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "loaded_spacy_model = en_core_web_md.load()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1406,  0.0046,  0.0920],\n         [ 0.1406,  0.0046,  0.0920],\n         [ 0.1406,  0.0046,  0.0920]],\n\n        [[ 0.0598,  0.0111, -0.0198],\n         [ 0.0598,  0.0111, -0.0198],\n         [ 0.0711, -0.0101, -0.0199]],\n\n        [[ 0.0173,  0.0219, -0.0438],\n         [ 0.0414, -0.0108, -0.0302],\n         [ 0.0351, -0.0206, -0.0155]]], grad_fn=<ViewBackward0>)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "  \"test1 test2 test3\",\n",
    "  \"test1 test2\",\n",
    "  \"test1\"\n",
    "]\n",
    "classes = [1, 2, 3]\n",
    "\n",
    "# [\n",
    "#   [(300), (300), (300)],\n",
    "#   [(300), (300)],\n",
    "#   [(300)]\n",
    "# ]\n",
    "sentences_vectors = []\n",
    "for sentence in sentences:\n",
    "  spacy_doc = loaded_spacy_model.make_doc(sentence)\n",
    "  word_vectors = [token.vector for token in spacy_doc]\n",
    "  sentences_vectors.append(word_vectors)\n",
    "\n",
    "# [\n",
    "#   tensor((300)),\n",
    "#   tensor((300)),\n",
    "#   tensor((300))\n",
    "# ]\n",
    "word_vectors_tensor = [torch.Tensor(sentence_vectors) for sentence_vectors in sentences_vectors]\n",
    "\n",
    "# tensor(\n",
    "#   tensor((300), (300), (300)),\n",
    "#   tensor((300), (300), (300)),\n",
    "#   tensor((300), (300), (300)), --> tensor (900)\n",
    "# )\n",
    "# (max_seq_len, batch_size, word_vector_dim)\n",
    "batch = pad_sequence(word_vectors_tensor)\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "lstm_input_size = 300\n",
    "lstm_hidden_size = 128\n",
    "lstm_num_layers = 1\n",
    "classes_number = 3\n",
    "\n",
    "# models\n",
    "lstm = torch.nn.LSTM(\n",
    "  input_size = lstm_input_size,\n",
    "  hidden_size = lstm_hidden_size,\n",
    "  num_layers = lstm_num_layers,\n",
    ")\n",
    "linear = torch.nn.Linear(lstm_hidden_size, classes_number)\n",
    "\n",
    "# word word word ..... -> class\n",
    "\n",
    "# forward step\n",
    "h0 = torch.ones(lstm_num_layers, batch.shape[1], lstm_hidden_size)\n",
    "c0 = torch.ones(lstm_num_layers, batch.shape[1], lstm_hidden_size)\n",
    "output_lstm, (final_hidden_state, final_cell_state) = lstm(batch, (h0, c0))\n",
    "output_linear = linear(output_lstm)\n",
    "output_linear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
